{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "849uSyTnblxg",
        "outputId": "729b3b64-03b5-4bf8-ea47-0cefa2ed5ff3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwwKnGAvV33L",
        "outputId": "690fe767-25b4-4d56-c368-96dc474b59ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# 정수 인코딩(Integer Encoding)\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize # 문장단위로 나눔\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english')) # 불용어 목록"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Rachel started AI Fundamentals course In Microsoft AI School last October. She got very nervous and passionate at the starting point of the course. She has yet to finish the course, but she has suffered from many happenings after the course started. Two months left. She will overcome all troubles. Every student will overcome their own troubles. Life is a journey to overcome all troubles.\"\n",
        "\n",
        "# 문장 분리\n",
        "sentences = sent_tokenize(text)\n",
        "for sentence in sentences:\n",
        "    print(sentence, '\\n')\n",
        "\n",
        "\n",
        "vocab = {} # 빈 딕셔너리 생성\n",
        "encoded_sentences = [] # 빈 리스트 생성\n",
        "\n",
        "\n",
        "# 문장별로 토큰화\n",
        "for sentence in sentences:\n",
        "    tokenized_sentence = word_tokenize(sentence)\n",
        "    result = []\n",
        "\n",
        "    for word in tokenized_sentence:\n",
        "        word = word.lower() # 소문자 변환(단어 개수 줄이기)\n",
        "        if word not in stop_words: # 불용어 제거\n",
        "            if len(word) > 1: # 단어 길이 2부터\n",
        "                result.append(word) # 단어를 추가한다\n",
        "                if word not in vocab: # 딕셔너리에 없는 단어 빈도수 0으로 초기화\n",
        "                    vocab[word] = 0\n",
        "                vocab[word] += 1 # 단어 빈도수 1 증가\n",
        "    encoded_sentences.append(result)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "for encoded_sentence in encoded_sentences:\n",
        "    print(encoded_sentence, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHrqoNePbhzi",
        "outputId": "c0973f54-9920-42f9-a363-b02a8a886e9e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rachel started AI Fundamentals course In Microsoft AI School last October. \n",
            "\n",
            "She got very nervous and passionate at the starting point of the course. \n",
            "\n",
            "She has yet to finish the course, but she has suffered from many happenings after the course started. \n",
            "\n",
            "Two months left. \n",
            "\n",
            "She will overcome all troubles. \n",
            "\n",
            "Every student will overcome their own troubles. \n",
            "\n",
            "Life is a journey to overcome all troubles. \n",
            "\n",
            "\n",
            "\n",
            "['rachel', 'started', 'ai', 'fundamentals', 'course', 'microsoft', 'ai', 'school', 'last', 'october'] \n",
            "\n",
            "['got', 'nervous', 'passionate', 'starting', 'point', 'course'] \n",
            "\n",
            "['yet', 'finish', 'course', 'suffered', 'many', 'happenings', 'course', 'started'] \n",
            "\n",
            "['two', 'months', 'left'] \n",
            "\n",
            "['overcome', 'troubles'] \n",
            "\n",
            "['every', 'student', 'overcome', 'troubles'] \n",
            "\n",
            "['life', 'journey', 'overcome', 'troubles'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MFOWqqMUcbP4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}